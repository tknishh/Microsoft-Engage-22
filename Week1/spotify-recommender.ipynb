{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-05T15:49:10.168539Z","iopub.execute_input":"2022-05-05T15:49:10.168849Z","iopub.status.idle":"2022-05-05T15:49:10.181878Z","shell.execute_reply.started":"2022-05-05T15:49:10.168815Z","shell.execute_reply":"2022-05-05T15:49:10.181253Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport plotly.express as px \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import euclidean_distances\nfrom scipy.spatial.distance import cdist\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:49:10.183720Z","iopub.execute_input":"2022-05-05T15:49:10.184070Z","iopub.status.idle":"2022-05-05T15:49:12.785097Z","shell.execute_reply.started":"2022-05-05T15:49:10.184043Z","shell.execute_reply":"2022-05-05T15:49:12.784253Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/spotify-dataset/data/data.csv\")\ngenre_data = pd.read_csv('../input/spotify-dataset/data/data_by_genres.csv')\nyear_data = pd.read_csv('../input/spotify-dataset/data/data_by_year.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:49:12.786358Z","iopub.execute_input":"2022-05-05T15:49:12.786644Z","iopub.status.idle":"2022-05-05T15:49:13.590458Z","shell.execute_reply.started":"2022-05-05T15:49:12.786613Z","shell.execute_reply":"2022-05-05T15:49:13.589604Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data[234:239]","metadata":{"execution":{"iopub.status.busy":"2022-05-05T16:02:01.034979Z","iopub.execute_input":"2022-05-05T16:02:01.035322Z","iopub.status.idle":"2022-05-05T16:02:01.058470Z","shell.execute_reply.started":"2022-05-05T16:02:01.035267Z","shell.execute_reply":"2022-05-05T16:02:01.057650Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:49:13.616534Z","iopub.execute_input":"2022-05-05T15:49:13.617117Z","iopub.status.idle":"2022-05-05T15:49:13.759199Z","shell.execute_reply.started":"2022-05-05T15:49:13.617071Z","shell.execute_reply":"2022-05-05T15:49:13.758342Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from yellowbrick.target import FeatureCorrelation\n\nfeature_names = ['acousticness', 'danceability', 'energy', 'instrumentalness',\n       'liveness', 'loudness', 'speechiness', 'tempo', 'valence','duration_ms','explicit','key','mode','year']\n\nX, y = data[feature_names], data['popularity']\n\n# Create a list of the feature names\nfeatures = np.array(feature_names)\n\n# Instantiate the visualizer\nvisualizer = FeatureCorrelation(labels=features)\n\nplt.rcParams['figure.figsize']=(20,20)\nvisualizer.fit(X, y)     # Fit the data to the visualizer\nvisualizer.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:49:13.760543Z","iopub.execute_input":"2022-05-05T15:49:13.760849Z","iopub.status.idle":"2022-05-05T15:49:14.265180Z","shell.execute_reply.started":"2022-05-05T15:49:13.760810Z","shell.execute_reply":"2022-05-05T15:49:14.264442Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"top10_genres = genre_data.nlargest(10, 'popularity')\n\nfig = px.bar(top10_genres, x='genres', y=['valence', 'energy', 'danceability', 'acousticness'], barmode='group')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:49:14.266226Z","iopub.execute_input":"2022-05-05T15:49:14.266489Z","iopub.status.idle":"2022-05-05T15:49:15.159128Z","shell.execute_reply.started":"2022-05-05T15:49:14.266461Z","shell.execute_reply":"2022-05-05T15:49:15.158560Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\ncluster_pipeline = Pipeline([('scaler', StandardScaler()), ('kmeans', KMeans(n_clusters=10))])\nX = genre_data.select_dtypes(np.number)\ncluster_pipeline.fit(X)\ngenre_data['cluster'] = cluster_pipeline.predict(X)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:49:37.806894Z","iopub.execute_input":"2022-05-05T15:49:37.807190Z","iopub.status.idle":"2022-05-05T15:49:39.362963Z","shell.execute_reply.started":"2022-05-05T15:49:37.807158Z","shell.execute_reply":"2022-05-05T15:49:39.357379Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Visualizing the Clusters with t-SNE\n\nfrom sklearn.manifold import TSNE\n\ntsne_pipeline = Pipeline([('scaler', StandardScaler()), ('tsne', TSNE(n_components=2, verbose=1))])\ngenre_embedding = tsne_pipeline.fit_transform(X)\nprojection = pd.DataFrame(columns=['x', 'y'], data=genre_embedding)\nprojection['genres'] = genre_data['genres']\nprojection['cluster'] = genre_data['cluster']\n\nfig = px.scatter(\n    projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'genres'])\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:49:41.906362Z","iopub.execute_input":"2022-05-05T15:49:41.907181Z","iopub.status.idle":"2022-05-05T15:49:57.348592Z","shell.execute_reply.started":"2022-05-05T15:49:41.907129Z","shell.execute_reply":"2022-05-05T15:49:57.347717Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"song_cluster_pipeline = Pipeline([('scaler', StandardScaler()), \n                                  ('kmeans', KMeans(n_clusters=20, \n                                   verbose=False))\n                                 ], verbose=False)\n\nX = data.select_dtypes(np.number)\nnumber_cols = list(X.columns)\nsong_cluster_pipeline.fit(X)\nsong_cluster_labels = song_cluster_pipeline.predict(X)\ndata['cluster_label'] = song_cluster_labels","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:50:35.360894Z","iopub.execute_input":"2022-05-05T15:50:35.361193Z","iopub.status.idle":"2022-05-05T15:50:48.753708Z","shell.execute_reply.started":"2022-05-05T15:50:35.361161Z","shell.execute_reply":"2022-05-05T15:50:48.752986Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Visualizing the Clusters with PCA\n\nfrom sklearn.decomposition import PCA\n\npca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2))])\nsong_embedding = pca_pipeline.fit_transform(X)\nprojection = pd.DataFrame(columns=['x', 'y'], data=song_embedding)\nprojection['title'] = data['name']\nprojection['cluster'] = data['cluster_label']\n\nfig = px.scatter(\n    projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'title'])\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:50:48.755601Z","iopub.execute_input":"2022-05-05T15:50:48.756095Z","iopub.status.idle":"2022-05-05T15:50:52.090206Z","shell.execute_reply.started":"2022-05-05T15:50:48.756051Z","shell.execute_reply":"2022-05-05T15:50:52.089417Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"!pip install spotipy\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nfrom collections import defaultdict\n\nsp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=\"548d04ea46c943f984b48ecc463c0149\",\n                                                           client_secret=\"16cec4c71ada469fb709ef716d56713c\"))\n\ndef find_song(name, year):\n    song_data = defaultdict()\n    results = sp.search(q= 'track: {} year: {}'.format(name,year), limit=1)\n    if results['tracks']['items'] == []:\n        return None\n\n    results = results['tracks']['items'][0]\n    track_id = results['id']\n    audio_features = sp.audio_features(track_id)[0]\n\n    song_data['name'] = [name]\n    song_data['year'] = [year]\n    song_data['explicit'] = [int(results['explicit'])]\n    song_data['duration_ms'] = [results['duration_ms']]\n    song_data['popularity'] = [results['popularity']]\n\n    for key, value in audio_features.items():\n        song_data[key] = value\n\n    return pd.DataFrame(song_data)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:53:39.206512Z","iopub.execute_input":"2022-05-05T15:53:39.206818Z","iopub.status.idle":"2022-05-05T15:53:39.217559Z","shell.execute_reply.started":"2022-05-05T15:53:39.206785Z","shell.execute_reply":"2022-05-05T15:53:39.216494Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\nfrom sklearn.metrics import euclidean_distances\nfrom scipy.spatial.distance import cdist\nimport difflib\n\nnumber_cols = ['valence', 'year', 'acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\n 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'popularity', 'speechiness', 'tempo']\n\n\ndef get_song_data(song, spotify_data):\n    \n    try:\n        song_data = spotify_data[(spotify_data['name'] == song['name']) \n                                & (spotify_data['year'] == song['year'])].iloc[0]\n        return song_data\n    \n    except IndexError:\n        return find_song(song['name'], song['year'])\n        \n\ndef get_mean_vector(song_list, spotify_data):\n    \n    song_vectors = []\n    \n    for song in song_list:\n        song_data = get_song_data(song, spotify_data)\n        if song_data is None:\n            print('Warning: {} does not exist in Spotify or in database'.format(song['name']))\n            continue\n        song_vector = song_data[number_cols].values\n        song_vectors.append(song_vector)  \n    \n    song_matrix = np.array(list(song_vectors))\n    return np.mean(song_matrix, axis=0)\n\n\ndef flatten_dict_list(dict_list):\n    \n    flattened_dict = defaultdict()\n    for key in dict_list[0].keys():\n        flattened_dict[key] = []\n    \n    for dictionary in dict_list:\n        for key, value in dictionary.items():\n            flattened_dict[key].append(value)\n            \n    return flattened_dict\n\n\ndef recommend_songs( song_list, spotify_data, n_songs=10):\n    \n    metadata_cols = ['name', 'year', 'artists']\n    song_dict = flatten_dict_list(song_list)\n    \n    song_center = get_mean_vector(song_list, spotify_data)\n    scaler = song_cluster_pipeline.steps[0][1]\n    scaled_data = scaler.transform(spotify_data[number_cols])\n    scaled_song_center = scaler.transform(song_center.reshape(1, -1))\n    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n    index = list(np.argsort(distances)[:, :n_songs][0])\n    \n    rec_songs = spotify_data.iloc[index]\n    rec_songs = rec_songs[~rec_songs['name'].isin(song_dict['name'])]\n    return rec_songs[metadata_cols].to_dict(orient='records')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:55:44.637218Z","iopub.execute_input":"2022-05-05T15:55:44.637534Z","iopub.status.idle":"2022-05-05T15:55:44.654709Z","shell.execute_reply.started":"2022-05-05T15:55:44.637505Z","shell.execute_reply":"2022-05-05T15:55:44.653849Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"data[18963:18969]","metadata":{"execution":{"iopub.status.busy":"2022-05-05T16:08:33.053182Z","iopub.execute_input":"2022-05-05T16:08:33.053738Z","iopub.status.idle":"2022-05-05T16:08:33.078679Z","shell.execute_reply.started":"2022-05-05T16:08:33.053687Z","shell.execute_reply":"2022-05-05T16:08:33.077507Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"recommend_songs([{'name': 'Who Says', 'year':2009},\n                {'name': 'Return/Gone', 'year': 1921},\n                {'name': 'For the First Time', 'year': 2011 },\n                {'name': 'Deja Vu', 'year': 2016},\n                {'name': 'Heartbreak Warfare', 'year': 2009}],  data)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T16:08:56.617826Z","iopub.execute_input":"2022-05-05T16:08:56.618635Z","iopub.status.idle":"2022-05-05T16:08:56.820186Z","shell.execute_reply.started":"2022-05-05T16:08:56.618597Z","shell.execute_reply":"2022-05-05T16:08:56.819310Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}